{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Tagging With A LSTM-CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fourth post in my series about named entity recognition. If you haven’t seen the last three, have a look now. The last time we used a recurrent neural network to model the sequence structure of our sentences. Now we use a hybrid approach combining a bidirectional LSTM model and a CRF model. The so called LSTM-CRF is a state-of-the-art approach to named entity recognition.\n",
    "\n",
    "Let’s recall the situation from my post about conditional random fields. We are given a input sequence $x = (x_1,\\dots, x_m)$, i.e. the words of a sentence and a sequence of output states $s = (s_1,\\dots, s_m)$, i.e. the named entity tags. In conditional random fields we modeled the conditional probability\n",
    "\n",
    "\n",
    "<center>\\[p(s_1,\\dots,s_m|x_1,\\dots,x_m)\\]</center>\n",
    "\n",
    "\n",
    "of the output state sequence give a input sequence. We did this by defining a feature map\n",
    "\n",
    "\n",
    "<center>\\[\\Phi(x_1,\\dots,x_m,s_1,\\dots,s_m)\\in\\mathbb{R}^d\\]</center>  \n",
    "\n",
    "\n",
    "that maps an entire input sequence x paired with an entire state sequence s to some d-dimensional feature vector. Then we can model the probability as a log-linear model with the parameter vector $w\\in\\mathbb{R}^d$\n",
    "\n",
    "\n",
    "<center>\\[p(s|x; w) = \\frac{\\exp(w\\cdot\\Phi(x, s))}{\\sum_{s^\\prime} \\exp(w\\cdot\\Phi(x, s^\\prime))},\\]</center>\n",
    "\n",
    "\n",
    "where $s^\\prime$ ranges over all possible output sequences. We can view the expression $w\\cdot\\Phi(x, s) = \\text{score}_{crf}(x,s)$ as a scoring how well the state sequence fits the given input sequence. The idea is now, to replace the linear scoring function by a non-linear neural network. So we define the score\n",
    "\n",
    "\n",
    "<center>\\[\\text{score}_{lstm-crf}(x,s) = \\sum_{i=0}^n W_{s_{i-1}, s_i} \\cdot \\text{LSTM}(x)_i + b_{s_{i-1},s_i},\\]</center>\n",
    "\n",
    "\n",
    "where $W_{s_{i-1}, s_i}$ and b are the weight vector and the bias corresponding to the transition from $s_{i-1}$ to $s_i$, respectively.\n",
    "\n",
    "\n",
    "Note, that the score functions are also called $\\textit{potential functions}$. After constructing this score function, we can optimize the conditional probability $p(s|x; W, b)$ like in the usual CRF and propagating back trough the network. We are going to use the implementation provided by the keras-contrib package, that contains useful extensions to the official keras package.\n",
    "\n",
    "Now dive into the applied part. We start as always by loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS Tag\n",
       "1048570  Sentence: 47959       they  PRP   O\n",
       "1048571  Sentence: 47959  responded  VBD   O\n",
       "1048572  Sentence: 47959         to   TO   O\n",
       "1048573  Sentence: 47959        the   DT   O\n",
       "1048574  Sentence: 47959     attack   NN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 47959 sentences containing 35178 different words with 17 different tags. We use the SentenceGetter class from last post to retrieve sentences with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how a sentence looks now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that looks like expected, now get all sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we introduce dictionaries of words and tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "idx2word = {i + 1: w for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22849"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"Obama\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx[\"ENDPAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"B-geo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we map the senctences to a sequence of numbers and then pad the sequence. Note that we increased the index of the words by one to use zero as a padding value. This is done because we want to use the mask_zeor parameter of the embedding layer to ignore inputs with value zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19622, 34454,  8413,  5032, 22283, 13662, 10666, 12397,   528,\n",
       "        2791,  1320, 34811, 17334, 23628,  3832,  2791, 12765, 34454,\n",
       "       19398, 22384,  3263, 24459, 31293, 33853, 35179, 35179, 35179,\n",
       "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
       "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
       "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
       "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
       "       35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179, 35179,\n",
       "       35179, 35179, 35179], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to do the same for our tag sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the network we also need to change the labels y to categorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split in train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup the CRF-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit a LSTM-CRF network with an embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ennoh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/ennoh/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20, input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True, recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ennoh/anaconda3/envs/py36/lib/python3.6/site-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "/Users/ennoh/anaconda3/envs/py36/lib/python3.6/site-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 20)            703600    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 100)           28400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 75, 17)            1190      \n",
      "=================================================================\n",
      "Total params: 738,240\n",
      "Trainable params: 738,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ennoh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n",
      "38846/38846 [==============================] - 144s 4ms/step - loss: 0.1076 - crf_viterbi_accuracy: 0.9697 - val_loss: 0.0431 - val_crf_viterbi_accuracy: 0.9848\n",
      "Epoch 2/5\n",
      "38846/38846 [==============================] - 142s 4ms/step - loss: 0.0321 - crf_viterbi_accuracy: 0.9882 - val_loss: 0.0275 - val_crf_viterbi_accuracy: 0.9893\n",
      "Epoch 3/5\n",
      "38846/38846 [==============================] - 147s 4ms/step - loss: 0.0238 - crf_viterbi_accuracy: 0.9905 - val_loss: 0.0239 - val_crf_viterbi_accuracy: 0.9901\n",
      "Epoch 4/5\n",
      "38846/38846 [==============================] - 148s 4ms/step - loss: 0.0208 - crf_viterbi_accuracy: 0.9914 - val_loss: 0.0230 - val_crf_viterbi_accuracy: 0.9903\n",
      "Epoch 5/5\n",
      "38846/38846 [==============================] - 149s 4ms/step - loss: 0.0192 - crf_viterbi_accuracy: 0.9919 - val_loss: 0.0220 - val_crf_viterbi_accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=5, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_crf_viterbi_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>crf_viterbi_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043120</td>\n",
       "      <td>0.984844</td>\n",
       "      <td>0.107617</td>\n",
       "      <td>0.969715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027528</td>\n",
       "      <td>0.989267</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>0.988193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.990147</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>0.990477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022956</td>\n",
       "      <td>0.990324</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>0.991381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.990527</td>\n",
       "      <td>0.019184</td>\n",
       "      <td>0.991882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_crf_viterbi_accuracy      loss  crf_viterbi_accuracy\n",
       "0  0.043120                  0.984844  0.107617              0.969715\n",
       "1  0.027528                  0.989267  0.032091              0.988193\n",
       "2  0.023941                  0.990147  0.023828              0.990477\n",
       "3  0.022956                  0.990324  0.020803              0.991381\n",
       "4  0.022035                  0.990527  0.019184              0.991882"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(hist[\"crf_viterbi_accuracy\"])\n",
    "plt.plot(hist[\"val_crf_viterbi_accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our model systematically. You can find the details in this post, here we just apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4796/4796 [==============================] - 5s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(X_te, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 81.8%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      per       0.78      0.76      0.77      1719\n",
      "      geo       0.85      0.87      0.86      3968\n",
      "      tim       0.88      0.84      0.86      2013\n",
      "      gpe       0.96      0.91      0.93      1561\n",
      "      org       0.68      0.68      0.68      2145\n",
      "      art       0.00      0.00      0.00        39\n",
      "      eve       1.00      0.03      0.05        38\n",
      "      nat       0.00      0.00      0.00        21\n",
      "\n",
      "micro avg       0.83      0.81      0.82     11504\n",
      "macro avg       0.82      0.81      0.81     11504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "Patriarch      : B-org B-per\n",
      "Bartholomew    : I-org I-per\n",
      "called         : O     O\n",
      "it             : O     O\n",
      "proof          : O     O\n",
      "that           : O     O\n",
      "there          : O     O\n",
      "are            : O     O\n",
      "no             : O     O\n",
      "insurmountable : O     O\n",
      "problems       : O     O\n",
      "in             : O     O\n",
      "the            : O     O\n",
      "Church         : B-tim B-org\n",
      "of             : I-tim I-org\n",
      "Christ         : I-tim I-org\n",
      ".              : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n",
      "ENDPAD         : O     O\n"
     ]
    }
   ],
   "source": [
    "i = 1927\n",
    "p = model.predict(np.array([X_te[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "true = np.argmax(y_te[i], -1)\n",
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(X_te[i], true, p[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(words[w-1], tags[t], tags[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good and it did require any feature engineering. The power of the CRF is not really visible here, but if we had a dataset with more complicated named entites this would be quite strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference With The LSTM-CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPDATE: Since many people asked how to use this with new data, which is obviously important, I show you now how to do it. To stay in the frame of this tutorial, I will assume the text is already tokenized. If you don’t know how to do this, I recommend looking at my post about word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = [\"Hawking\", \"was\", \"a\", \"Fellow\", \"of\", \"the\", \"Royal\", \"Society\", \",\", \"a\", \"lifetime\", \"member\",\n",
    "                 \"of\", \"the\", \"Pontifical\", \"Academy\", \"of\", \"Sciences\", \",\", \"and\", \"a\", \"recipient\", \"of\",\n",
    "                 \"the\", \"Presidential\", \"Medal\", \"of\", \"Freedom\", \",\", \"the\", \"highest\", \"civilian\", \"award\",\n",
    "                 \"in\", \"the\", \"United\", \"States\", \".\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transform every word to it’s integer index. Note that we mapping unknown words to zero. Normally you would want to add a UNKNOWN token to your vocabulary. Then you cut the vocabulary on which you train the model and replace all uncommon words by the UNKNOWN token. We haven’t done this for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can predict with the model and see what we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||Prediction\n",
      "==============================\n",
      "Hawking        : I-gpe\n",
      "was            : O    \n",
      "a              : O    \n",
      "Fellow         : O    \n",
      "of             : O    \n",
      "the            : O    \n",
      "Royal          : B-org\n",
      "Society        : I-org\n",
      ",              : O    \n",
      "a              : O    \n",
      "lifetime       : O    \n",
      "member         : O    \n",
      "of             : O    \n",
      "the            : O    \n",
      "Pontifical     : B-org\n",
      "Academy        : I-org\n",
      "of             : I-org\n",
      "Sciences       : I-org\n",
      ",              : O    \n",
      "and            : O    \n",
      "a              : O    \n",
      "recipient      : O    \n",
      "of             : O    \n",
      "the            : O    \n",
      "Presidential   : O    \n",
      "Medal          : I-gpe\n",
      "of             : O    \n",
      "Freedom        : B-org\n",
      ",              : O    \n",
      "the            : O    \n",
      "highest        : O    \n",
      "civilian       : O    \n",
      "award          : O    \n",
      "in             : O    \n",
      "the            : O    \n",
      "United         : B-geo\n",
      "States         : I-geo\n",
      ".              : O    \n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([x_test_sent[0]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "print(30 * \"=\")\n",
    "for w, pred in zip(test_sentence, p[0]):\n",
    "    print(\"{:15}: {:5}\".format(w, tags[pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you enjoied this post and learned something that you can apply in your daily work. Next time I show you how you can improve the model even further by using character-level embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
